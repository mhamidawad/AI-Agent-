# agent.toml
version = "1.0"

[commands.my_agent]
description = "Detailed description for users"
instructions = """
Your agent's behavior instructions here.
Be specific about the task and expected outcomes.
"""

arguments = [
    { name = "input_file", type = "string", required = true, description = "Input file path" },
    { name = "threshold", type = "number", required = false, default = 0.8, description = "Quality threshold" },
    { name = "model", type = "string", required = false, description = "Which LLM model to use" }
]

# âœ… Model support
models = [
  "gpt-4.1",
  "gpt-4o",
  "o3",
  "o4-mini",
  "claude-4-sonnet",
  "gemini-2.5-pro",
  "grok-4",
  "kimi-k2"
]

mcpServers = """
{
    "custom-shell": {
      "command": "uvx",
      "args": [
        "mcp-shell-server"
      ],
      "env": {
        "ALLOW_COMMANDS": "..."
      }
    },
    "github": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "GITHUB_PERSONAL_ACCESS_TOKEN",
        "ghcr.io/github/github-mcp-server"
      ]
    }
}
"""

tools = ["filesystem", "git", "shell", "github"]

execution_strategy = "act"

output_schema = """
{
    "properties": {
        "success": {"type": "boolean"},
        "results": {"type": "array", "items": {"type": "string"}},
        "score": {"type": "number"}
    }
}
"""

exit_expression = "success"
